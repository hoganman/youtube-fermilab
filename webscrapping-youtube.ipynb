{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NLP Comment Parsing on the FermiLab YouTube Channel\n",
    "\n",
    "This notebook is a simple analysis of comments on the YouTube channel Fermilab on popular topics in physics. The comments parsed are using the NLP library called spacy\n",
    "\n",
    "This does NOT use the YouTube API is probably a violation of fair use policy. I do not endorse this solution nor should this notebook be considered an endorsement.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "from typing import Optional, Literal, Final, List, Dict\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.remote.webdriver import WebDriver\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "from selenium.webdriver.common.by import By\n",
    "import spacy\n",
    "import tomli"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T13:41:35.084298Z",
     "end_time": "2023-04-14T13:41:35.105296Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the pre-trained embedding 'en_core_web_lg' for token similarity in Spacy. BeautifulSoup is used for html parsing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Select a video from the Subatomic Stories series: \"3 Subatomic Stories: Charged leptons\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "vid_url: Final[str] = (\n",
    "    # u\"https://www.youtube.com/watch?v=ilwMM-CEO6w\"\n",
    "    u\"https://www.youtube.com/watch?v=RN10TgkPCbQ\"\n",
    "    # u\"https://www.youtube.com/watch?v=jtp3Jk-nKhQ\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T13:41:35.100298Z",
     "end_time": "2023-04-14T13:41:35.127297Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define some helper functions to parse YouTube comments without the API"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matthew\\AppData\\Local\\Temp\\ipykernel_1792\\114777334.py:34: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(chrome_driver_path)\n"
     ]
    }
   ],
   "source": [
    "def get_chrome_driver(\n",
    "    driver_exe: Optional[os.PathLike] = None,\n",
    ") -> Optional[WebDriver]:\n",
    "    \"\"\"Get the Chrome driver executable for Selenium. The driver is\n",
    "    searched in the environment variable 'PATH'\n",
    "\n",
    "    Args:\n",
    "        driver_exe: Path of executable (default=\"chromedriver\")\n",
    "\n",
    "    Returns:\n",
    "        Chrome webdriver if executable found, else None\n",
    "    \"\"\"\n",
    "    driver: WebDriver\n",
    "\n",
    "    if driver_exe is None:\n",
    "        driver_exe = \"chromedriver\"\n",
    "\n",
    "    if Path(driver_exe).exists():\n",
    "        return webdriver.Chrome(driver_exe)\n",
    "\n",
    "    split_token: Literal[\";\", \":\"] = \":\"\n",
    "    if \"win\" in sys.platform:\n",
    "        split_token = \";\"\n",
    "        driver_exe += \".exe\"\n",
    "    chrome_driver_path: Optional[Path] = None\n",
    "\n",
    "    for file_path in os.environ.get(\"PATH\").split(split_token):\n",
    "        temp_file = Path(file_path) / driver_exe\n",
    "        if temp_file.exists():\n",
    "            chrome_driver_path = temp_file\n",
    "            break\n",
    "\n",
    "    if chrome_driver_path is not None and chrome_driver_path.exists():\n",
    "        driver = webdriver.Chrome(chrome_driver_path)\n",
    "        return driver\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_driver(\n",
    "    driver_type: Literal[\"chrome\"] = \"chrome\",\n",
    "    driver_exe: Optional[os.PathLike] = None,\n",
    ") -> Optional[WebDriver]:\n",
    "    \"\"\"Get the specified driver for Selenium\n",
    "\n",
    "    Args:\n",
    "        driver_type: Type of driver like 'chrome'\n",
    "        driver_exe: PathLike executable\n",
    "\n",
    "    Returns:\n",
    "        Webdriver if executable found, else None\n",
    "    \"\"\"\n",
    "    if driver_type == \"chrome\":\n",
    "        return get_chrome_driver(driver_exe)\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_yt_comments(\n",
    "    vid_url: str,\n",
    "    pages: int = 7,\n",
    "    min_sleep_sec: float = 2.0\n",
    ") -> List[str]:\n",
    "    \"\"\"Obtain Youtube comments as a list of unicode strings. Due to the nature of\n",
    "    this algorithm, this violates YouTube fair use policy and will NOT be used in\n",
    "    production code. This function is unable to extract more than 100 comments.\n",
    "\n",
    "    Args:\n",
    "        vid_url: URL of video on Youtube\n",
    "        pages: Number comment pages to load\n",
    "        min_sleep_sec: Wait time between comment page scrolling\n",
    "\n",
    "    Returns:\n",
    "         Comments list\n",
    "    \"\"\"\n",
    "    comments: List[str]\n",
    "\n",
    "    driver = get_driver()\n",
    "    if driver is None:\n",
    "        raise TypeError(\"Unable to get web driver!\")\n",
    "    driver.get(vid_url)\n",
    "    driver.maximize_window()\n",
    "\n",
    "    # Scroll to first comments page\n",
    "    time.sleep(2 * min_sleep_sec)\n",
    "    driver.execute_script(\"window.scrollTo(0, 1000);\")\n",
    "\n",
    "    for _ in range(pages - 1):\n",
    "      time.sleep(min_sleep_sec)\n",
    "      driver.execute_script(\"window.scrollTo(0, 10000);\")\n",
    "\n",
    "    comments_section: WebElement\n",
    "    [comments_section] = driver.find_elements(\n",
    "        by=By.XPATH,\n",
    "        value='//*[@id=\"comments\"]'\n",
    "    )\n",
    "    comments_html: Final[str] = comments_section.get_attribute(\"innerHTML\")\n",
    "\n",
    "    # parse the HTML content with BeautifulSoup\n",
    "    soup: BeautifulSoup = BeautifulSoup(markup=comments_html, features=\"html.parser\")\n",
    "    comments = [\n",
    "        comment.text\n",
    "        for comment in soup.find_all(\n",
    "            name=\"yt-formatted-string\",\n",
    "            attrs={\"class\": \"style-scope ytd-comment-renderer\"}\n",
    "        )\n",
    "    ]\n",
    "    return comments\n",
    "\n",
    "\n",
    "video_comments = get_yt_comments(vid_url, pages=8, min_sleep_sec=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T13:41:35.119295Z",
     "end_time": "2023-04-14T13:41:45.506296Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "100"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(video_comments)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T13:41:45.503299Z",
     "end_time": "2023-04-14T13:41:45.522297Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We got 100 comments which is small but a modest start.\n",
    "\n",
    "Let's load a hand-picked glossary of terms that map pop-culture terminology to over-arching topics.\n",
    "\n",
    "This is what one entry is like\n",
    "\n",
    "```toml\n",
    "neutrino = [\"neutrino\", \"oscillation\", \"ghost\", \"mass\"]\n",
    "```\n",
    "\n",
    "The topic 'neutrino' is often associated with itself and other words like 'oscillation', 'mass', and 'ghost' as in ghost particle."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "with Path(\"data/dict.toml\").open(mode=\"rb\") as fp:\n",
    "    physics_glossary = tomli.load(fp)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T13:41:45.519296Z",
     "end_time": "2023-04-14T13:41:45.563295Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "nlp_web = spacy.load(\"en_core_web_lg\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T13:41:45.536297Z",
     "end_time": "2023-04-14T13:41:46.779296Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For spacy to make token similarity calculations using an inner-product space embedding, we need to convert each word into a token"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "spacy.tokens.doc.Doc"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physics_glossary_nlp: Dict[str, List[spacy.tokens.doc.Doc]] = {\n",
    "    key: [nlp_web(val) for val in values]\n",
    "    for key, values in physics_glossary.items()\n",
    "}\n",
    "# type(physics_glossary_nlp[\"quark\"][0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T13:41:46.781298Z",
     "end_time": "2023-04-14T13:41:46.969297Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This algorithm attempts to match comment tokens with the load pop-culture glossary. The threshold was picked such that the words 'quark' and 'quarks' were similar. Another metric to include might be to calculate the edit distance (number of insertions, deletions, and swaps) for word similarity.\n",
    "\n",
    "The model/algorithm assumes a single comment asks at most a single question or discussion with a single over-arching topic. To break degeneracy, a Counter.most_common() method is used."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matthew\\AppData\\Local\\Temp\\ipykernel_1792\\886224180.py:17: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  temp_similarity = token.similarity(glossary_token)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "up up 1.0\n",
      "up up 1.0\n",
      "quantum quantum 1.0\n",
      "up up 1.0\n",
      "neutrinos neutrino 0.9374495466930591\n",
      "neutrinos neutrino 0.9374495466930591\n",
      "dark dark 1.0\n",
      "top top 1.0\n",
      "quark quark 1.0\n",
      "bottom bottom 1.0\n",
      "force force 1.0\n",
      "force force 1.0\n",
      "quark quark 1.0\n",
      "annihilate annihilate 1.0\n",
      "quark quark 1.0\n",
      "up up 1.0\n",
      "quark quark 1.0\n",
      "down down 1.0\n",
      "quark quark 1.0\n",
      "quantum quantum 1.0\n",
      "quarks quark 0.8979578916015317\n",
      "annihilate annihilate 1.0\n",
      "pairs pairs 1.0\n",
      "annihilate annihilate 1.0\n",
      "pairs pairs 1.0\n",
      "gravitational gravitational 1.0\n",
      "gravitational oscillation 0.8086236853918781\n",
      "fragmentation oscillation 0.8116312590820531\n",
      "fragmentation dilation 0.806441297694348\n",
      "quarks quark 0.8979578916015317\n",
      "big big 1.0\n",
      "quark quark 1.0\n",
      "quark quark 1.0\n",
      "dimension dimension 1.0\n",
      "dimension dimension 1.0\n",
      "quarks quark 0.8979578916015317\n",
      "neutrinos neutrino 0.9374495466930591\n",
      "universe universe 1.0\n",
      "neutrino neutrino 1.0\n",
      "quarks quark 0.8979578916015317\n",
      "quark quark 1.0\n",
      "antimatter antimatter 1.0\n",
      "quark quark 1.0\n",
      "annihilate annihilate 1.0\n",
      "quarks quark 0.8979578916015317\n",
      "quarks quark 0.8979578916015317\n",
      "white black 0.8708782459085267\n",
      "neutrinos neutrino 0.9374495466930591\n",
      "neutron neutrino 0.8424156872842373\n",
      "feynman feynman 1.0\n",
      "down down 1.0\n",
      "quark quark 1.0\n",
      "up up 1.0\n",
      "quark quark 1.0\n",
      "down down 1.0\n",
      "quark quark 1.0\n",
      "neutrino neutrino 1.0\n",
      "up up 1.0\n",
      "quark quark 1.0\n",
      "neutrino neutrino 1.0\n",
      "weak weak 1.0\n",
      "neutrinos neutrino 0.9374495466930591\n",
      "neutrinos neutrino 0.9374495466930591\n",
      "light light 1.0\n",
      "ftl ftl 1.0\n",
      "neutrinos neutrino 0.9374495466930591\n",
      "neutrinos neutrino 0.9374495466930591\n",
      "antimatter antimatter 1.0\n",
      "force force 1.0\n",
      "quantum quantum 1.0\n",
      "foam foam 1.0\n",
      "waves waves 1.0\n",
      "force force 1.0\n",
      "neutrinos neutrino 0.9374495466930591\n",
      "neutrinos neutrino 0.9374495466930591\n",
      "graviton gravity 0.8578810006351206\n",
      "quark quark 1.0\n",
      "weak weak 1.0\n",
      "force force 1.0\n",
      "neutrinos neutrino 0.9374495466930591\n",
      "up up 1.0\n",
      "quark quark 1.0\n",
      "bottom bottom 1.0\n",
      "quark quark 1.0\n",
      "up up 1.0\n",
      "bottom bottom 1.0\n",
      "annihilate annihilate 1.0\n",
      "up up 1.0\n",
      "quark quark 1.0\n",
      "annihilate annihilate 1.0\n",
      "mass mass 1.0\n",
      "quark quark 1.0\n",
      "strong strong 1.0\n",
      "force force 1.0\n",
      "quark quark 1.0\n",
      "mass mass 1.0\n",
      "quark quark 1.0\n",
      "quark quark 1.0\n",
      "quarks quark 0.8979578916015317\n",
      "up up 1.0\n",
      "down down 1.0\n",
      "strange strange 1.0\n",
      "up up 1.0\n",
      "quark quark 1.0\n",
      "annihilate annihilate 1.0\n",
      "up up 1.0\n",
      "up up 1.0\n",
      "up up 1.0\n",
      "up up 1.0\n",
      "quark quark 1.0\n",
      "mass mass 1.0\n",
      "mass mass 1.0\n",
      "quarks quark 0.8979578916015317\n",
      "antimatter antimatter 1.0\n",
      "universe universe 1.0\n",
      "quantum quantum 1.0\n",
      "charm charm 1.0\n",
      "top top 1.0\n",
      "bottom bottom 1.0\n",
      "strange strange 1.0\n",
      "universe universe 1.0\n",
      "up up 1.0\n",
      "down down 1.0\n",
      "mass mass 1.0\n",
      "universe universe 1.0\n",
      "quarks quark 0.8979578916015317\n",
      "higgs higgs 1.0\n",
      "quarks quark 0.8979578916015317\n",
      "quarks quark 0.8979578916015317\n",
      "pauli pauli 1.0\n",
      "exclusion exclusion 1.0\n",
      "principle principle 1.0\n",
      "force force 1.0\n",
      "exclusion exclusion 1.0\n",
      "principle principle 1.0\n",
      "up up 1.0\n",
      "em em 1.0\n",
      "annihilate annihilate 1.0\n",
      "antimatter antimatter 1.0\n",
      "waves waves 1.0\n",
      "symmetry supersymmetry 0.8768450276782127\n",
      "feynman feynman 1.0\n",
      "down down 1.0\n",
      "quark quark 1.0\n",
      "up up 1.0\n",
      "quark quark 1.0\n",
      "up up 1.0\n",
      "quark quark 1.0\n",
      "up up 1.0\n",
      "quark quark 1.0\n",
      "down down 1.0\n",
      "quark quark 1.0\n",
      "quarks quark 0.8979578916015317\n",
      "quark quark 1.0\n",
      "annihilate annihilate 1.0\n",
      "quark quark 1.0\n",
      "strong strong 1.0\n",
      "force force 1.0\n",
      "quark quark 1.0\n",
      "mass mass 1.0\n",
      "up up 1.0\n",
      "quarks quark 0.8979578916015317\n",
      "down down 1.0\n",
      "quark quark 1.0\n",
      "up up 1.0\n",
      "mass mass 1.0\n",
      "mass mass 1.0\n",
      "strong strong 1.0\n",
      "force force 1.0\n",
      "quarks quark 0.8979578916015317\n",
      "mass mass 1.0\n",
      "up up 1.0\n",
      "mass mass 1.0\n",
      "mass mass 1.0\n",
      "higgs higgs 1.0\n",
      "mass mass 1.0\n",
      "quark quark 1.0\n",
      "antimatter antimatter 1.0\n",
      "gravity gravity 1.0\n",
      "gravity gravity 1.0\n"
     ]
    }
   ],
   "source": [
    "min_required_similarity = 0.80\n",
    "key_counts: Dict[str, int] = defaultdict(int)\n",
    "\"\"\"Dictionary of the popularity of topics for each comment\"\"\"\n",
    "# Get comment tokens that are alphabetic\n",
    "for comment in video_comments:\n",
    "    comment_keys: List[str] = []\n",
    "    for token in nlp_web(comment.lower()):\n",
    "        if len(token.text) < 2:\n",
    "            continue\n",
    "        if not token.is_alpha:\n",
    "            continue\n",
    "        # Find the most discussed topic in the comment using the glossary\n",
    "        for key, glossary_tokens in physics_glossary_nlp.items():\n",
    "            for glossary_token in glossary_tokens:\n",
    "                store_key = False\n",
    "                temp_similarity = token.similarity(glossary_token)\n",
    "                if temp_similarity > min_required_similarity:\n",
    "                    store_key = True\n",
    "                # Other logic here if necessary\n",
    "                if store_key is True:\n",
    "                    print(token.text, glossary_token.text, temp_similarity)\n",
    "                    comment_keys.append(key)\n",
    "    if len(comment_keys) == 0:\n",
    "        continue\n",
    "    # Use most_common() method on Counter to get descending sorted key list and then key\n",
    "    most_common_key = Counter(comment_keys).most_common()[0][0]\n",
    "    key_counts[most_common_key] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T13:41:46.973298Z",
     "end_time": "2023-04-14T13:41:52.142298Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "defaultdict(int,\n            {'quark': 20,\n             'quantum': 5,\n             'neutrino': 11,\n             'antimatter': 4,\n             'cosmos': 3,\n             'exotic': 2,\n             'force': 7,\n             'higgs': 1})"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_counts"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T13:41:52.142298Z",
     "end_time": "2023-04-14T13:41:52.188295Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As expected, most of the comments are about quarks, which are the most well known charged leptons. Other comments include neutral leptons like the neutrino and other physics like the Higgs boson."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
